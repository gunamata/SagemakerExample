{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Deploy Your First Machine Learning Model on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker session\n",
    "\n",
    "A SageMaker session needs to be initialized in order to start interacting the SageMaker service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker as sage\n",
    "\n",
    "boto_session = boto3.Session(profile_name=\"up-sagemaker\")\n",
    "session = sage.Session(boto_session=boto_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the iris data for training \n",
    "\n",
    "Using the SageMaker session, which was initialized in the previous cell, the Iris data will be upload to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_directory = 'data'\n",
    "s3_prefix = 'up-sagemaker-iris'\n",
    "\n",
    "data_location = session.upload_data(local_data_directory, key_prefix=s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator and fit the model\n",
    "\n",
    "In order to use SageMaker to fit our algorithm, we'll create an `Estimator` that defines how to use the container to train. This includes the configuration we need to invoke SageMaker training:\n",
    "\n",
    "* The __container name__. This is constructed as in the shell commands above.\n",
    "* The __role__. As defined above.\n",
    "* The __instance count__ which is the number of machines to use for training.\n",
    "* The __instance type__ which is the type of machine to use for training.\n",
    "* The __output path__ determines where the model artifact will be written.\n",
    "* The __session__ is the SageMaker session object that we defined above.\n",
    "\n",
    "Then we use fit() on the estimator to train against the data that we uploaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-23 17:48:42 Starting - Starting the training job...\n",
      "2020-03-23 17:48:43 Starting - Launching requested ML instances......\n",
      "2020-03-23 17:49:47 Starting - Preparing the instances for training...\n",
      "2020-03-23 17:50:36 Downloading - Downloading input data\n",
      "2020-03-23 17:50:36 Training - Downloading the training image...\n",
      "2020-03-23 17:51:18 Uploading - Uploading generated training model\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2020-03-23 17:51:24 Completed - Training job completed\n",
      "Training seconds: 54\n",
      "Billable seconds: 54\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "account = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = session.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/first-ml-model:latest'.format(account, region)\n",
    "\n",
    "role = get_execution_role(session)\n",
    "estimator = sage.estimator.Estimator(\n",
    "                        image,\n",
    "                        role, \n",
    "                        1, \n",
    "                        'ml.m4.xlarge',\n",
    "                        output_path=\"s3://{}/output\".format(session.default_bucket()),\n",
    "                        sagemaker_session=session\n",
    ")\n",
    "\n",
    "estimator.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model\n",
    "\n",
    "Using the trained `Estimator`, a RESTful service will be initialized on Amazon SageMaker service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer\n",
    "\n",
    "predictor = estimator.deploy(1, 'ml.m4.xlarge', serializer=json_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample some data and use it for a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feat_1': [5.8, 5.4, 5.0, 6.4, 5.7, 5.8, 5.4, 4.8, 5.0, 5.5],\n",
       " 'feat_2': [2.7, 3.9, 3.4, 3.2, 2.5, 2.6, 3.9, 3.1, 3.0, 4.2],\n",
       " 'feat_3': [3.9, 1.7, 1.6, 5.3, 5.0, 4.0, 1.3, 1.6, 1.6, 1.4],\n",
       " 'feat_4': [1.2, 0.4, 0.4, 2.3, 2.0, 1.2, 0.4, 0.2, 0.2, 0.2]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"data/iris.csv\", header=None, names=[\"feat_1\", \"feat_2\", \"feat_3\", \"feat_4\"])\n",
    "\n",
    "sampled_df = data_df.sample(10)\n",
    "\n",
    "sampled_post_request_body = sampled_df.to_dict(orient='list')\n",
    "\n",
    "sampled_post_request_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [\"versicolor\", \"setosa\", \"setosa\", \"virginica\", \"virginica\", \"versicolor\", \"setosa\", \"setosa\", \"setosa\", \"setosa\"]}\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(sampled_post_request_body).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
